# Campaigns Run - Refactoring Plan

## Overview

This document provides detailed instructions for refactoring the three campaign scripts from `backend/scripts/` to work within the `backend/run/campaigns_run/` module structure. These scripts will be updated to use the centralized `backend/utils/` modules, update to Leo2 Firebase database, sync messages to Airtable instead of Firebase, and provide main functions that can be called from a central orchestrator.

---

## Scripts to Refactor

1. **fill_the_table.py** - Fill The Table Campaign
2. **return_to_table.py** - Return To Table Campaign
3. **seat_newcomers.py** - Seat Newcomers Campaign

---

## Refactoring Tasks

### Task 1: Update Import Paths

**Objective:** Update all helper module imports to point to `backend/utils/` instead of the old `helpers/` directory.

**Current Import Structure (in scripts/):**
```python
# Current imports from scripts folder
root_dir = os.path.join(script_dir, '../..')
sys.path.insert(0, root_dir)
from helpers.report_creation.report_generator import generate_report
from helpers.firebase_manage.firebase_manager import FirebaseManager
from helpers.mongodb_pull import MongoDBPull
```

**New Import Structure (for run/campaigns_run/):**
```python
# New imports from run/campaigns_run folder
# Add backend/utils to path
import os
import sys

# Get path to backend/utils
backend_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../..')
utils_dir = os.path.join(backend_dir, 'utils')
sys.path.insert(0, backend_dir)

# Import from utils modules
from utils.report_creation.report_generator import generate_report
from utils.firebase_manage.firebase_manager import FirebaseManager
from utils.mongodb_pull.mongodb_pull import MongoDBPull
```

**Directory Structure Reference:**
```
backend/
‚îú‚îÄ‚îÄ run/
‚îÇ   ‚îî‚îÄ‚îÄ campaigns_run/
‚îÇ       ‚îú‚îÄ‚îÄ README.md (this file)
‚îÇ       ‚îú‚îÄ‚îÄ fill_the_table.py
‚îÇ       ‚îú‚îÄ‚îÄ return_to_table.py
‚îÇ       ‚îú‚îÄ‚îÄ seat_newcomers.py
‚îÇ       ‚îî‚îÄ‚îÄ run_campaigns.py (orchestrator)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ fill-the-table/
‚îÇ   ‚îú‚îÄ‚îÄ return-to-table/
‚îÇ   ‚îî‚îÄ‚îÄ seat-newcomers/
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ airtable_sync/
    ‚îú‚îÄ‚îÄ firebase_manage/
    ‚îú‚îÄ‚îÄ mongodb_pull/
    ‚îî‚îÄ‚îÄ report_creation/
```

**Instructions:**
1. Copy each script from `backend/scripts/<script-name>/` to `backend/run/campaigns_run/`
2. Update the path calculation to account for new location (2 levels up to backend/)
3. Change import statements from `helpers.` to `utils.`
4. Ensure logging throughout all operations with INFO level for key steps and DEBUG for detailed operations

---

### Task 2: Update Firebase Database from "Leo" to "Leo2"

**Objective:** Update the Firebase base path configuration in `firebase_manager.py` to point to "Leo2" instead of "Leo" database.

**Location to Update:**
- File: `backend/utils/firebase_manage/firebase_manager.py`

**Current Configuration:**
```python
# In firebase_manager.py
self.firebase_base_path = os.getenv('FIREBASE_BASE_PATH', 'Leo')
```

**Updated Configuration:**
```python
# In firebase_manager.py
self.firebase_base_path = os.getenv('FIREBASE_BASE_PATH', 'Leo2')
```

**Alternative Approach (Environment Variable):**
If you want to keep the code flexible, update your `.env` file instead:
```bash
# In .env file
FIREBASE_BASE_PATH=Leo2
```

**Instructions:**
1. Open `backend/utils/firebase_manage/firebase_manager.py`
2. Locate the `firebase_base_path` initialization (likely in `__init__` method or `_init_firebase`)
3. Change default value from `'Leo'` to `'Leo2'`
4. Test Firebase connectivity to ensure Leo2 database is accessible
5. Add logging: `logger.info(f"Using Firebase database: {self.firebase_base_path}")`

---

### Task 3: Create Main Functions for Each Script

**Objective:** Refactor each campaign script to have a `main()` function that accepts inputs and returns messages_array, users_array, and events_array (those that it filtered for), making them callable from an orchestrator script.

**Current Structure:**
```python
# Current: Scripts run directly with hardcoded logic
def run(self):
    # ... complex logic ...
    # No return value
```

**New Structure:**
```python
def main(users_data: List[Dict],
         events_data: List[Dict],
         matching_prompt: str,
         message_generation_prompt: str,
         logger: logging.Logger = None) -> Tuple[List[Dict], List[Dict], List[Dict]]:
    """
    Main function to run the campaign with provided data.

    Args:
        users_data: List of user dictionaries from MongoDB
        events_data: List of event dictionaries from MongoDB
        matching_prompt: Custom prompt template for user-event matching
        message_generation_prompt: Custom prompt template for message generation
        logger: Optional logger instance

    Returns:
        Tuple of (messages_array, users_array, events_array):
        - messages_array: List of message dictionaries generated by the campaign
        - users_array: List of user dictionaries that were filtered/used in this campaign
        - events_array: List of event dictionaries that were filtered/used in this campaign
    """
    # Initialize campaign with provided data
    campaign = CampaignClass(logger=logger)

    # Use provided data instead of fetching
    campaign.users = users_data
    campaign.events = events_data

    # Use custom prompts
    campaign.matching_prompt_template = matching_prompt
    campaign.message_generation_prompt_template = message_generation_prompt

    # Run campaign logic
    messages = campaign.run_campaign()
    
    # Extract users and events that were actually used/filtered for this campaign
    # This should include only users/events that were matched and had messages generated
    used_user_ids = set(msg.get('user_id') for msg in messages)
    used_event_ids = set(msg.get('event_id') for msg in messages)
    
    filtered_users = [u for u in users_data if u.get('id') in used_user_ids]
    filtered_events = [e for e in events_data if e.get('id') in used_event_ids]

    # Log summary with good detail
    logger.info(f"Campaign completed: {len(messages)} messages generated")
    logger.info(f"Filtered users: {len(filtered_users)}, Filtered events: {len(filtered_events)}")

    return messages, filtered_users, filtered_events
```

**Instructions for Each Script:**

1. **Extract Main Logic to Reusable Function:**
   - Separate data fetching from processing
   - Accept users_data and events_data as parameters
   - Accept prompt templates as parameters
   - Return tuple of (messages_array, users_array, events_array) instead of saving to Firebase/Airtable
   - Track which users and events were actually used/filtered for this campaign

2. **Update Campaign Class Constructor:**
   ```python
   def __init__(self,
                users_data: List[Dict] = None,
                events_data: List[Dict] = None,
                logger: logging.Logger = None):
       """
       Initialize campaign with optional pre-loaded data.
       If data not provided, fetch from MongoDB.
       """
       self.logger = logger or logging.getLogger(self.__class__.__name__)

       # Use provided data or fetch
       if users_data is not None and events_data is not None:
           self.users = users_data
           self.events = events_data
           self.logger.info("Using provided user and event data")
       else:
           self.logger.info("Fetching user and event data from MongoDB")
           self.users = self.get_users()
           self.events = self.get_events()
   ```

3. **Add Logging Throughout:**
   - Log at start of main function with parameters received
   - Log progress through major steps (matching, message generation)
   - Log statistics (matches created, messages generated)
   - Log errors with full context and stack traces
   - Log completion with summary stats

---

### Task 4: Combine and Dedupe Campaign Results

**Objective:** Create a task/function that takes the messages_array, users_array, and events_array from each campaign and combines them into single arrays with deduplication, ensuring the campaigns field represents all campaigns each item came from.

**Location:** This should be part of the orchestrator script `run_campaigns.py`

**Implementation:**
```python
def combine_campaign_results(campaign_results: List[Dict]) -> Dict[str, List[Dict]]:
    """
    Combine results from multiple campaigns, deduplicating while preserving campaign sources.
    
    Args:
        campaign_results: List of dicts with keys:
            - 'campaign_name': str (e.g., 'fill-the-table', 'return-to-table', 'seat-newcomers')
            - 'messages': List[Dict]
            - 'users': List[Dict]
            - 'events': List[Dict]
    
    Returns:
        Dict with keys 'messages', 'users', 'events', each containing deduplicated arrays
        where each item has a 'campaigns' field (list) showing all campaigns it came from
    """
    combined_messages = {}  # key: unique identifier, value: message dict
    combined_users = {}     # key: user_id, value: user dict
    combined_events = {}    # key: event_id, value: event dict
    
    for result in campaign_results:
        campaign_name = result['campaign_name']
        
        # Process messages - dedupe by user_id (one message per user)
        for msg in result['messages']:
            user_id = msg.get('user_id')
            if user_id:
                if user_id not in combined_messages:
                    # First time seeing this user - create new message
                    msg_copy = msg.copy()
                    msg_copy['campaigns'] = [campaign_name]
                    combined_messages[user_id] = msg_copy
                else:
                    # User already has a message - add campaign to list
                    if campaign_name not in combined_messages[user_id]['campaigns']:
                        combined_messages[user_id]['campaigns'].append(campaign_name)
        
        # Process users - dedupe by user_id
        for user in result['users']:
            user_id = user.get('id')
            if user_id:
                if user_id not in combined_users:
                    user_copy = user.copy()
                    user_copy['campaigns'] = [campaign_name]
                    combined_users[user_id] = user_copy
                else:
                    if campaign_name not in combined_users[user_id]['campaigns']:
                        combined_users[user_id]['campaigns'].append(campaign_name)
        
        # Process events - dedupe by event_id
        for event in result['events']:
            event_id = event.get('id')
            if event_id:
                if event_id not in combined_events:
                    event_copy = event.copy()
                    event_copy['campaigns'] = [campaign_name]
                    combined_events[event_id] = event_copy
                else:
                    if campaign_name not in combined_events[event_id]['campaigns']:
                        combined_events[event_id]['campaigns'].append(campaign_name)
    
    return {
        'messages': list(combined_messages.values()),
        'users': list(combined_users.values()),
        'events': list(combined_events.values())
    }
```

**Save Combined Results Locally:**
```python
def save_combined_results(combined_results: Dict[str, List[Dict]], output_dir: str):
    """
    Save combined results to local JSON files compatible with airtable_sync.py
    
    Args:
        combined_results: Dict with 'messages', 'users', 'events' keys
        output_dir: Directory to save files (should be backend/utils/mongodb_pull/data/)
    """
    import os
    import json
    
    os.makedirs(output_dir, exist_ok=True)
    
    # Save each array to separate JSON files
    for data_type in ['messages', 'users', 'events']:
        file_path = os.path.join(output_dir, f'{data_type}.json')
        with open(file_path, 'w') as f:
            json.dump(combined_results[data_type], f, indent=2, default=str)
        
        logger.info(f"‚úì Saved {len(combined_results[data_type])} {data_type} to {file_path}")
```

**Compatibility with airtable_sync.py:**
- The `airtable_sync.py` script expects data files in `backend/utils/mongodb_pull/data/`
- Files should be named: `messages.json`, `users.json`, `events.json`
- Each file should contain a JSON array of objects
- The `campaigns` field (list) will be preserved in the data structure

**Instructions:**
1. Implement `combine_campaign_results()` function in orchestrator script
2. Implement `save_combined_results()` function to save to `backend/utils/mongodb_pull/data/`
3. After all campaigns run, call combine function with all campaign results
4. Save combined results to local JSON files
5. Ensure the `campaigns` field is a list (not a string) to represent all campaigns
6. Log deduplication statistics (e.g., "X messages from 3 campaigns, Y unique users, Z unique events")

---

### Task 5: Use MongoDB Pull Script for Data Fetching

**Objective:** Use the existing `mongodb_pull.py` script from `backend/utils/mongodb_pull/` to fetch users and events data for campaigns instead of creating a new utility script.

**Location:** Use directly in orchestrator script `run_campaigns.py`

**Available Methods in mongodb_pull.py:**
- `MongoDBPull.users_pull()` - Fetches enriched users data with campaign qualifications
- `MongoDBPull.events_pull()` - Fetches enriched events data with campaign qualifications

**Usage Example:**
```python
from utils.mongodb_pull.mongodb_pull import MongoDBPull

# Initialize MongoDB connection
mongodb_pull = MongoDBPull(logger=logger)

# Fetch all users (enriched with campaign qualifications)
all_users = mongodb_pull.users_pull(
    generate_report=False,  # Don't generate report, just return data
    save_data=False  # Don't save to local files (we'll handle that separately)
)

# Fetch all events (enriched with campaign qualifications)
all_events = mongodb_pull.events_pull(
    generate_report=False,
    save_data=False
)

# Filter users by campaign qualification
def filter_users_by_campaign(users, campaign_type):
    """Filter users that qualify for a specific campaign."""
    qualification_field = f'qualifies_{campaign_type}'
    return [
        user for user in users
        if user.get('campaign_qualifications', {}).get(qualification_field, False)
    ]

# Filter events by campaign qualification
def filter_events_by_campaign(events, campaign_type):
    """Filter events that qualify for a specific campaign."""
    qualification_field = f'qualifies_{campaign_type}'
    return [
        event for event in events
        if event.get('campaign_qualifications', {}).get(qualification_field, False)
    ]

# Example: Get users and events for fill_the_table campaign
fill_table_users = filter_users_by_campaign(all_users, 'fill_the_table')
fill_table_events = filter_events_by_campaign(all_events, 'fill_the_table')

# Close connection when done
mongodb_pull.close()
```

**Campaign Type Mapping:**
- `'fill_the_table'` ‚Üí qualification field: `qualifies_fill_the_table`
- `'return_to_table'` ‚Üí qualification field: `qualifies_return_to_table`
- `'seat_newcomers'` ‚Üí qualification field: `qualifies_seat_newcomers`

**Instructions:**
1. Import `MongoDBPull` from `utils.mongodb_pull.mongodb_pull` in orchestrator script
2. Initialize `MongoDBPull` instance once at the start
3. Call `users_pull()` and `events_pull()` once to get all data
4. Filter users/events by campaign qualification fields as needed
5. Pass filtered data to each campaign's `main()` function
6. Close MongoDB connection when all campaigns complete
7. Add comprehensive logging for:
   - MongoDB connection establishment
   - Number of users/events fetched
   - Filter results for each campaign
   - Any errors encountered

---

## Campaign Prompts

### Fill The Table Campaign

#### Matching Prompt
```
You are an expert event marketer focused on filling underbooked events.

PRIORITY: Match users to this event which has LOW participation ({fill_rate:.1f}% full, {remaining} spots remaining). Your goal is to maximize attendance for events that need more participants.

MATCHING CRITERIA (in order of importance):
1. Spots left and urgency (event starts soon)
2. Interest alignment between user interests and event categories/features
3. Location proximity (user neighborhood vs event neighborhood)
4. User engagement history (event attendance count + recency)
5. Professional background relevance

Return a JSON array of match objects. Each object must contain:
- 'user_name': The user's full name (exact match from list below)
- 'event_name': "{event_name}"
- 'reasoning': Brief explanation focusing on why this match helps fill the event AND why the user would be interested
- 'confidence_percentage': Number 0-100 (prioritize matches for low-fill events)
- 'match_purpose': "fill_low_participation"

Select the best 5-10 matches for this event. Higher confidence scores should go to better matches.

Event:
Name: {event_name}
Summary: {event_summary}
Fill Rate: {fill_rate:.1f}% ({participants}/{max_participants} participants, {remaining} spots remaining)

Users:
{users_text}

Return only the JSON array, no additional text.
```

#### Message Generation Prompt
```
You are an expert SMS copywriter specializing in high-conversion, personalized messages for a social dining app.

GOAL: Drive RSVPs and attendance (fill underbooked events). Motivate immediate action.

SMS BEST PRACTICES:
1) LENGTH: <180 chars total (including link). Be concise.
2) TONE: Friendly, concise, 0‚Äì2 relevant emojis.
3) STRUCTURE: [Greeting + Name] [Hook tied to interests/occupation/location] [Spots left + time urgency + social proof] [CTA + link at end].
4) SCARCITY: Make spots left/time explicit; small-group feel when true.
5) SOCIAL PROOF: Mention participants already in if available.
6) PROXIMITY: Call out neighborhood convenience explicitly.
7) CTA: Tie directly to link ("Tap to RSVP: {event_link}"); link must be last.
8) PERSONALIZATION: Adjust tone for age/gender/role; if engagement_status is dormant/churned or days_inactive > 30, add a warm welcome-back/reunion vibe and nod to time away. If active, keep momentum.
9) AVOID: ALL CAPS, multiple questions, generic hype, long sentences, excessive punctuation.

EXAMPLES (with links):
- "Hey Sarah! üçú Ramen night Thu 7:30p near Midtown, 4 spots left‚Äîcozy group, Japanese flavors you love. Tap to RSVP: https://cucu.li/bookings/12345"
- "Hi Mike! Comedy + dinner near West Village tomorrow, only 3 seats‚Äîfriends already in. Tap to RSVP: https://cucu.li/bookings/12345"
- "Hi Priya! Mexican supper near SoMa, 2 spots left; walkable from you. Tap to RSVP: https://cucu.li/bookings/12345"

Match context:
{match_summary}

Return a JSON object:
- message_text (must end with {event_link})
- personalization_notes
- character_count
```

---

### Return To Table Campaign

#### Matching Prompt
```
You are an expert user reactivation specialist focused on re-engaging dormant users.

PRIORITY: Find the SINGLE BEST event for this dormant user (31-90 days inactive) that will re-engage them and drive an RSVP.

MATCHING CRITERIA (in order of importance):
1. Interest alignment: User interests MUST match event categories/features (this is critical)
2. Location proximity: Prefer events in or near user's neighborhood
3. Event quality: Prefer events with HIGH participation (50-100% filled) to show social proof and quality
4. Reactivation potential: Events similar to their past attendance patterns
5. Event timing: Prefer events happening soon (creates urgency for reactivation)
6. Welcome back vibe: Events that feel welcoming for returning users

IMPORTANT:
- Return ONLY the SINGLE BEST match (not multiple)
- Prioritize events with higher participation (50-100% filled) over empty events
- The goal is to reactivate this user with a high-quality, engaging event
- Quality and relevance are more important than filling empty events

Return a JSON object (not array) with:
- 'event_name': The event name (exact match from list below)
- 'event_id': The event ID (REQUIRED - use the ID from the event list below)
- 'reasoning': Detailed explanation (3-4 sentences) focusing on why this specific event will reactivate THIS user, how interests align, why the event quality/participation makes it appealing, and why location/timing work for reactivation
- 'confidence_percentage': Number 0-100 (should be 80+ for a good match)
- 'match_purpose': "reactivate_dormant_user"

User:
Name: {user_name}
Summary: {user_summary}

Events:
{events_text}

Return only the JSON object, no additional text.
```

#### Message Generation Prompt
```
You are an expert SMS copywriter specializing in user reactivation for a social dining app.

GOAL: Re-engage dormant users (31-90 days inactive) and drive RSVPs to future events.

SMS BEST PRACTICES:
1) LENGTH: <180 chars total (including link). Be concise.
2) TONE: Warm, welcoming, friend-like. Acknowledge time away without being pushy.
3) STRUCTURE: [Greeting + Name] [Welcome back hook] [Event hook by interests/occupation/location] [Spots left + time urgency + social proof] [CTA + link at end].
4) REACTIVATION: Acknowledge they haven't been around ("We miss you!", "Welcome back!", "It's been a while!").
5) PERSONALIZATION: Reference specific interests, neighborhood convenience, occupation if relevant.
6) SCARCITY: Make spots left/time explicit; create urgency for reactivation.
7) SOCIAL PROOF: Mention participants already in if available.
8) CTA: Tie directly to link ("Tap to RSVP: {event_link}"); link must be last.
9) AVOID: ALL CAPS, multiple questions, generic hype, long sentences, excessive punctuation.

EXAMPLES (with links):
- "Hey Sarah! üëã We miss you! Ramen night Thu 7:30p near Midtown, 4 spots left‚Äîyour favorite Japanese flavors. Welcome back! Tap to RSVP: https://cucu.li/bookings/12345"
- "Hi Mike! It's been a while! Comedy + dinner near West Village tomorrow, only 3 seats‚Äîfriends already in. Tap to RSVP: https://cucu.li/bookings/12345"
- "Hi Priya! Welcome back! üéâ Mexican supper near SoMa, 2 spots left; walkable from you. Tap to RSVP: https://cucu.li/bookings/12345"

Match context:
{match_summary}

Return a JSON object:
- message_text (must end with {event_link})
- personalization_notes
- character_count
```

---

### Seat Newcomers Campaign

#### Matching Prompt
```
You are an expert user onboarding specialist focused on converting new users to their first event attendance.

PRIORITY: Find the SINGLE BEST event for this newcomer that will convert them to RSVP to their FIRST table.

MATCHING CRITERIA (in order of importance):
1. Interest alignment: User interests MUST match event categories/features (this is critical for first-timers)
2. Location proximity: Prefer events in or near user's neighborhood for convenience
3. Event welcomingness: Prefer events with GOOD participation (50-80% filled) to show quality without feeling exclusive
4. Beginner-friendly: Consider events with welcoming descriptions, group-friendly features
5. Event timing: Prefer events happening soon (creates urgency for first RSVP)
6. First-time appeal: Events that feel welcoming and not intimidating for newcomers

IMPORTANT:
- Return ONLY the SINGLE BEST match (not multiple)
- This is their FIRST (or one of their first) events - make it count!
- Prioritize events with moderate participation (50-80% filled) - good social proof, not too exclusive
- The goal is to convert this user to their first RSVP
- Quality and relevance are critical for first-time conversion

Return a JSON object (not array) with:
- 'event_name': The event name (exact match from list below)
- 'event_id': The event ID (REQUIRED - use the ID from the event list below)
- 'reasoning': Detailed explanation (3-4 sentences) focusing on why this specific event is perfect for THIS user's FIRST table, how interests align (critical for first-timers), why the event is welcoming and beginner-friendly, and how location/timing work for first-time attendance
- 'confidence_percentage': Number 0-100 (should be 80+ for a good match)
- 'match_purpose': "convert_newcomer_first_table"

User:
Name: {user_name}
Summary: {user_summary}

Events:
{events_text}

Return only the JSON object, no additional text.
```

#### Message Generation Prompt
```
You are an expert SMS copywriter specializing in converting new users to their first event attendance.

GOAL: Convert newcomers (0-2 events attended) to RSVP to their FIRST table.

SMS BEST PRACTICES:
1) LENGTH: <180 chars total (including link). Be concise.
2) TONE: Warm, welcoming, encouraging. Make them feel excited about their first event.
3) STRUCTURE: [Greeting + Name] [Welcome to community hook] [Event hook by interests/occupation/location] [Spots left + time urgency + social proof] [CTA + link at end].
4) FIRST-TIME FOCUS: Welcome them ("Welcome to Cuculi!", "Ready for your first table?", "Join us for your first event!").
5) PERSONALIZATION: Reference specific interests, neighborhood convenience, occupation if relevant.
6) WELCOMING: Emphasize that the event is welcoming, beginner-friendly, perfect for first-timers.
7) SCARCITY: Make spots left/time explicit; create urgency for first RSVP.
8) SOCIAL PROOF: Mention participants already in if available (shows community is active).
9) CTA: Tie directly to link ("Tap to RSVP: {event_link}"); link must be last.
10) AVOID: ALL CAPS, multiple questions, generic hype, long sentences, excessive punctuation, anything intimidating.

EXAMPLES (with links):
- "Hey Sarah! üëã Welcome to Cuculi! Your first table: Ramen night Thu 7:30p near SoHo, 4 spots left‚Äîperfect for your food love. Join us! Tap to RSVP: https://cucu.li/bookings/12345"
- "Hi Mike! Ready for your first table? Comedy + dinner near West Village tomorrow, only 3 seats‚Äîwelcoming group waiting. Tap to RSVP: https://cucu.li/bookings/12345"
- "Hi Priya! üéâ Welcome! Mexican supper near SoMa, 2 spots left; walkable from you. Perfect first event! Tap to RSVP: https://cucu.li/bookings/12345"

Match context:
{match_summary}

Return a JSON object:
- message_text (must end with {event_link})
- personalization_notes
- character_count
```

---

## Logging Requirements

### Comprehensive Logging Throughout

**All scripts must include comprehensive logging at INFO and DEBUG levels:**

#### INFO Level Logging:
- Script initialization and configuration
- Data fetching operations (users, events, messages)
- Number of records retrieved
- Campaign qualification filtering results
- Matching operations start/completion
- Each match created (user ‚Üí event)
- Message generation for each user
- Airtable/Firebase save operations
- Summary statistics (matches created, messages generated, errors)
- Campaign completion status

#### DEBUG Level Logging:
- Detailed MongoDB query parameters
- Field mapping operations
- API request/response details
- Data transformation steps
- Cache hits/misses
- Validation checks

#### Example Logging Pattern:
```python
# Start of operation
self.logger.info("=" * 80)
self.logger.info(f"Starting {self.campaign_name} Campaign: {self.campaign_id}")
self.logger.info("=" * 80)

# Data operations
self.logger.info(f"Fetching users for {self.campaign_name}...")
users = self.get_users()
self.logger.info(f"‚úì Retrieved {len(users)} qualified users")
self.logger.debug(f"User IDs: {[u.get('id') for u in users[:5]]}")

# Processing
for idx, user in enumerate(users, 1):
    self.logger.info(f"Processing user {idx}/{len(users)}: {user.get('firstName')} {user.get('lastName')}")
    # ... processing ...

# Results
self.logger.info(f"‚úì Created {len(matches)} matches")
self.logger.info(f"‚úì Generated {len(messages)} messages")

# Errors
if errors:
    self.logger.error(f"‚úó Encountered {len(errors)} errors:")
    for error in errors:
        self.logger.error(f"  - {error}")

# Completion
self.logger.info("=" * 80)
self.logger.info("CAMPAIGN COMPLETED SUCCESSFULLY")
self.logger.info("=" * 80)
```

---

## Implementation Checklist

### For Each Script (fill_the_table.py, return_to_table.py, seat_newcomers.py):

- [ ] Copy script from `backend/scripts/<script-name>/` to `backend/run/campaigns_run/`
- [ ] Update import paths (Task 1)
  - [ ] Update path calculation for new location
  - [ ] Change `from helpers.` to `from utils.`
  - [ ] Test all imports resolve correctly
- [ ] Update Firebase to Leo2 (Task 2)
  - [ ] Update firebase_manager.py or .env
  - [ ] Test Firebase connectivity
- [ ] Create main() function (Task 3)
  - [ ] Accept users_data, events_data, prompts as parameters
  - [ ] Return tuple of (messages_array, users_array, events_array)
  - [ ] Track which users/events were filtered/used in this campaign
  - [ ] Make constructor accept optional pre-loaded data
- [ ] Combine and dedupe campaign results (Task 4)
  - [ ] Implement combine_campaign_results() function
  - [ ] Dedupe messages by user_id (one message per user)
  - [ ] Dedupe users by user_id
  - [ ] Dedupe events by event_id
  - [ ] Preserve campaigns field as list showing all campaigns
  - [ ] Save combined results to backend/utils/mongodb_pull/data/
  - [ ] Ensure compatibility with airtable_sync.py
- [ ] Add comprehensive logging (Throughout)
  - [ ] INFO level for major operations
  - [ ] DEBUG level for detailed operations
  - [ ] Error logging with full context
  - [ ] Summary statistics logging
- [ ] Test script independently
- [ ] Test script via orchestrator

### Additional Tasks:

- [ ] Use mongodb_pull script for data fetching (Task 5)
  - [ ] Import MongoDBPull from utils.mongodb_pull.mongodb_pull
  - [ ] Initialize MongoDBPull instance in orchestrator
  - [ ] Call users_pull() and events_pull() once
  - [ ] Filter users/events by campaign qualification fields
  - [ ] Close connection when done

- [ ] Create orchestrator script `run_campaigns.py` in `backend/run/campaigns_run/`
  - [ ] Import all three campaign scripts
  - [ ] Use MongoDBPull to fetch data once (Task 5)
  - [ ] Call each campaign's main() function (Task 3)
  - [ ] Collect results from all campaigns
  - [ ] Combine and dedupe results (Task 4)
  - [ ] Save combined results to backend/utils/mongodb_pull/data/
  - [ ] Generate combined report
  - [ ] Note: After saving, airtable_sync.py can be run on the saved data

---

## Testing Plan

### Unit Testing:
1. Test import paths resolve correctly
2. Test MongoDB data fetching using MongoDBPull
3. Test main() functions with sample data (verify return values)
4. Test combine_campaign_results() deduplication logic
5. Test save_combined_results() file writing
6. Test logging outputs

### Integration Testing:
1. Run each campaign script independently
2. Verify main() returns correct tuple structure
3. Verify combined results are properly deduplicated
4. Verify saved JSON files are in correct format
5. Check log files for completeness
6. Validate message format and content

### End-to-End Testing:
1. Run orchestrator script with all three campaigns
2. Verify all campaigns complete successfully
3. Verify combined results are saved to backend/utils/mongodb_pull/data/
4. Run airtable_sync.py on saved data to verify compatibility
5. Review combined reports
6. Monitor for errors and edge cases

---

## Environment Variables Required

```bash
# MongoDB
MONGODB_URI=mongodb+srv://...

# Firebase
FIREBASE_DATABASE_URL=https://cuculi-2c473.firebaseio.com
FIREBASE_BASE_PATH=Leo2

# Airtable sync will be run separately after campaigns complete
# See airtable_sync.py in backend/utils/airtable_sync/

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# Optional
SAVE_LOCAL=false
LOG_LEVEL=INFO
```

---

## Next Steps

1. Review this README thoroughly
2. Begin with Task 1 (Update import paths) for one script
3. Test thoroughly before proceeding to next task
4. Complete all tasks for one script before moving to next
5. Create orchestrator script last
6. Run end-to-end testing
7. Deploy to production

---

## Notes

- Always maintain backward compatibility where possible
- Keep original scripts in `backend/scripts/` as backup
- Test each change incrementally
- Document any deviations from this plan
- Add comprehensive logging at every step
- Handle errors gracefully and log with full context

---

*Last Updated: 2025-12-16*
